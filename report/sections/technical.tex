This chapter presents the results of our research into the technical
underpinnings of the Kinect as a sensing device. Section \ref{howitworks}
describes techniques implemented in the Kinect to produces depth maps, in terms
of standard concepts from the field of machine vision. Then, section
\ref{precision} presents measurements, estimates and published data, which
together characterise the precision of the Kinect as a measurement tool.

\section{Overview: What is a Kinect}

The Kinect device is a sensor array incorporating, most notably, a system for
depth measurement. This system relies on a technique that enables low-cost
implementations. Several founders of an Israeli technology firm, PrimeSense Ltd,
invented the technique sometime before 11 October 2005 \cite{ZALEVSKY:2007}.
Microsoft corp., in turn, began selling the Kinect-branded implementation on 10
November 2010 as an optional user interface for its consumer gaming platform,
the Xbox 360.


\subsection{Specifications}

Table \ref{tab:specs} provides an overview of the electronic components that
comprise the Kinect's sensor array.

\begin{table}[ht]
\centering
\begin{tabular}{l p{10cm}}
\toprule
Component & Description \\
\midrule

RGB Camera & Sensor ``very similar'' to Mi\-cron mt9v112 (1/6" VGA CMOS) but
``larger'' and with some di\-ffering reg\-isters. Bay\-er co\-lour pa\-ttern (RG,GB).
640x\-480 pixels, 8-bit at 30 Hz.  1280x\-1024 pixels at 10\-Hz if using Open\-NI backend
, though this is referred to as ``15Hz'' in low level pro\-tocol. UYVY co\-lour
for\-mat also possible at ``15 Hz'' framerate.\cite{FREENECT}\cite{RGBDEMO} \\

Infrared camera & Monochrome CMOS sensor (no reliable source for this). Three
options for pixel size: ``small'' (unspecified); 640x480; 1280x1024. Framerate
options are 15Hz and 30Hz, except at maximum resolution (~9Hz).\cite{FREENECT}
field of view at 57 degrees horizontal, 43 degrees vertical according to retail
description.\cite{PLAY} Range reportedly ``adjustable'' (unconfirmed source) \\ 

Depth stream & Uncompressed data stream 16 bits, though this causes device
bandwidth problems. Usable options: ``differential/RLE'' compressed 11-bit
stream; 10-bit stream; 11-bit stream (uncompressed? still to be confirmed). The
only usable pixel size is 640x480. Framerate: 30Hz. \cite{FREENECT} Depth range
1.2m to 3.5m according to retail description.\cite{PLAY} Actual range
capability: ~ 0.7m-0.6m (unconfirmed source).\\

Infrared projector & Although non-reliable internet documents refe the use of a
``laser'' to project the infrared speckle pattern, this is unconfirmed. One
patent application relating to the Kinect describes a projecting a ``pattern of
coherent radiation''.\cite{SHPUNT:2010-1} Section \ref{howitworks} provides more
detail regading the projection component. \\

Accelerometer & Kionix KXSD9 Series. Sensitivity: 819 counts per g of
acceleration. Reports device tilt relative to the
horizon.\cite{FREENECT}\cite{KIONIX}\\

Microphone & ``Multiarray'' microphone consisting of four microphone units. Each
microphone generates two streams of 32 bit signed little endian PCM samples at
16KHz. A ninth channel from the device provides a unified noise-cancelled signal
in 16-bit little endian PCM samples (16KHz).\cite{FREENECT}\\

\bottomrule
\end{tabular}
\caption{Specifications of the Kinect}
\label{tab:specs}
\end{table}


\section{Theory: How it works}
\label{howitworks}

Our assessment is that the kinect measures depth using a proprietary extension
of the standard computer vision process known as stereo triangulation. In this
section we describe the depth measurement implementation in relatively high
level terms, from the perspective of theoretical computer vision. These
descriptions are based on our interpretation of public records, including
patents and scholarly as well as casual articles. We also refer, though to a
lesser extent, to our own experiments with the Kinect.


\subsection{Stereo triangulation}
\label{sub:triang}

Figure \ref{fig:triang} shows the idealised configuration of two cameras,
$c_{l}$ and $c_{r}$, set up as a stereo unit, and a point, $p$, on an object
viewed by both cameras. In this model, we simplify: 
\begin{itemize}

    \item   the sensors as pinhole cameras;

    \item   the stereo set-up so that the cameras' normal lines are parallel;

    \item   the camera planes are ``flipped'' to the front of the focal points
    for ease of illustration.

\end{itemize}

\begin{figure}[ht]
    \begin{center}
        \input{tikz_figures/triangulation}
        \caption{``Standard'' stereo triangulation}
        \label{fig:triang}
    \end{center}
\end{figure}

The desired value is $Z_{p}$, i.e.\ the minimum distance from the $x-y$ plane to
$p$, or the ``depth measurement'' for that point. We obtain $Z_{p}$ from: 
\begin{itemize}

    \item the focal length ($f$);

    \item the inter-camera distance ($b$); and 

    \item the respective distances between left and right camera norms and the
    pixels corresponding to $p$ on the left and right image planes ($x_{l}$ and
    $x_{r}$),

\end{itemize}

using the similarity of triangles, which yields equation
\ref{eq:triang1}.
%todo show algebra to derive this
\begin{align} \label{eq:triang1}
    \frac{Z_p}{b} = \frac{Z_p - f}{b - x_l - x_r}
\end{align}


\subsection{Stereo triangulation: the Kinect way}

Figure \ref{fig:atriang} shows the triangulation model adapted, \emph{mutatis
mutandis}, to a depth camera ($c$) projector ($s$) pair. This is sometimes
referred to as ``active triangulation'' \cite{alexander1987}, since one replaces
one passive component (a camera) with an active one (a projector). The same
simplifications apply as in section \ref{sub:triang}. The projector replaces the
second camera here, and we distinguish the target point ($p_a$) on the object
plane from the corresponding point ($p_r$) on a predetermined reference plane.

\begin{figure}[ht]
    \begin{center}
        \input{tikz_figures/projection_triangulation}
        \caption{``Active'' stereo triangulation}
        \label{fig:atriang}
    \end{center}
\end{figure}

%todo uhm, notation for lines, again?
Now it is worth emphasising the order in which the Kinect proceeds: First, for
every image pixel $x_a$ corresponding to a point ($p_a$) registered by the depth
camera, the Kinect finds the matching reference image pixel $x_r$ corresponding
to a point ($p_r$) on the reference plane by solving the so-called
``correspondence problem'' discussed in section \ref{sub:corr}. Once a matching
reference point $p_r$ is found, the Kinect determines the disparity $d_i$ along
the $x$-axis in image space between the actual image of $p_a$ and the reference
image of $p_r$. With that obtained, is it possible to derive the desired ``depth
measurement'' for the given point, or the minimum distance from the depth
camera's focal point to the object plane, from: 
\begin{itemize}

    \item the focal length ($f$);

    \item the inter-camera distance ($b$);

    \item the disparity between $x_a$ and $x_r$ along the x-axis ($d_i$);

    \item the reference image depth ($Z_r$),

\end{itemize}

using the similarity of triangles, which yields equations \ref{eq:atriang1} and
\ref{eq:atriang2}. Substituting for the common variable $d_o$, we simplify to
obtain equation \ref{eq:atriang2}.
%todo show algebra to derive this
\begin{align} 
    \frac{d_o}{b} = \frac{Z_r - Z_a}{Z_r} \label{eq:atriang1}\\
    \frac{d_i}{f} = \frac{d_o}{Z_a} \label{eq:atriang2}
\end{align}
\begin{equation} \label{eq:atriang2}
    Z_a = \frac{Z_r}{d_i \frac{Z_r}{b f} + 1}
\end{equation}

\subsection{Correspondence problem}
\label{sub:corr}

In order to ca

%todo describe experiment with pictures... 

%\subsubsection{Experiment: pattern variation over distance}

%todo describe experiment with pictures... (first discuss whether useful with Jeroen)



\section{Precision of the intrument}
\label{precision}

%todo: just take data from article
In this section we describe the Kinect's characteristics as a depth measurement
tool, and notably the precision of the measurements.


\subsection{Depth precision}

\subsubsection{Sources of error}

\subsection{Depth image resolution}

\subsubsection{Sources of error}
